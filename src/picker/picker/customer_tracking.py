import rclpy
from rclpy.node import Node
from rclpy.action import ActionClient
from rclpy.executors import MultiThreadedExecutor
from rclpy.qos import QoSProfile, QoSHistoryPolicy, QoSReliabilityPolicy

from nav2_msgs.action import NavigateToPose
from geometry_msgs.msg import PoseStamped, Twist
from sensor_msgs.msg import Image, CameraInfo, CompressedImage
from cv_bridge import CvBridge
from turtlebot4_navigation.turtlebot4_navigator import TurtleBot4Navigator, TurtleBot4Directions
from ultralytics import YOLO

import numpy as np
if not hasattr(np, "float"):
    np.float = float

from tf_transformations import quaternion_from_euler
import numpy as np
import cv2
import threading
import math
import os
from ament_index_python.packages import get_package_share_directory
from .quadrant_checker import draw_rotated_axis, get_quadrant


# ì›¹ìº ì—ì„œ íƒì§€í•  ê°ì²´ í´ëž˜ìŠ¤ ID
DETECT_TARGET = [0]  # 0: blue_car, 1: green_car
EAST_YAW = 0.0  # map ê¸°ì¤€ ë™ìª½(0rad)ì´ë¼ê³  ê°€ì •

# ê° ì‚¬ë¶„ë©´ì— í•´ë‹¹í•˜ëŠ” ëª©í‘œ ì¢Œí‘œ (x, y, theta)
QUADRANT_TARGET_POSES = {
    1: (-5.69312, 5.59361, EAST_YAW),
    2: (-8.55142, 4.34779, EAST_YAW),
    3: (-7.87239, 1.90992, EAST_YAW),
    4: (-4.25377, 2.85634, EAST_YAW)
}


class IntegratedRobotTracker(Node):
    def __init__(self):
        super().__init__('integrated_robot_tracker')
        self.get_logger().info('Integrated ë…¸ë“œê°€ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.')

        # ===== ê³µí†µ ì„¤ì • =====
        self.bridge = CvBridge()
        self.lock = threading.Lock()

        # ===== ëª¨ë¸ ê²½ë¡œ ì„¤ì • =====
        # ROS2 íŒ¨í‚¤ì§€ì˜ share ë””ë ‰í† ë¦¬ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
        try:
            package_share_dir = get_package_share_directory('picker')
            models_dir = os.path.join(package_share_dir, 'models')
        except:
            # íŒ¨í‚¤ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©
            script_dir = os.path.dirname(os.path.abspath(__file__))
            models_dir = os.path.join(script_dir, '../../../models')
        
        webcam_model_path = os.path.join(models_dir, 'webcam_final.pt')
        amr_model_path = os.path.join(models_dir, 'amr_final.pt')

        # ===== ì›¹ìº  ì„¤ì • (MoveRobot íŒŒíŠ¸) =====
        self.webcam_model = YOLO(webcam_model_path)
        self.cap = cv2.VideoCapture('/dev/video0')
        if not self.cap.isOpened():
            self.get_logger().warn("ì¹´ë©”ë¼ ì—°ê²° ëŠì–´ì§. ë‹¤ì‹œ ì—°ê²° ì¤‘...")
            self.cap.release()
            self.cap = cv2.VideoCapture('/dev/video0')
            raise IOError
        
        self.axis_angle = 40

        # ì›¹ìº  annotated ì´ë¯¸ì§€ í¼ë¸”ë¦¬ì…”
        self.webcam_image_publisher = self.create_publisher(Image, '/webcam/annotated_frame', 10)

        # Nav2 ì•¡ì…˜ í´ë¼ì´ì–¸íŠ¸
        self._action_client = ActionClient(self, NavigateToPose, 'navigate_to_pose')

        self.previous_quadrant = -1
        self.navigation_goal_handle = None
        self.navigation_in_progress = False

        # ===== OAK-D ì¹´ë©”ë¼ ì„¤ì • (DepthToMap íŒŒíŠ¸) =====
        self.qos_sensor = QoSProfile(
            history=QoSHistoryPolicy.KEEP_LAST,
            depth=1,
            reliability=QoSReliabilityPolicy.BEST_EFFORT
        )

        ns = self.get_namespace()
        self.depth_topic = f'{ns}/oakd/stereo/image_raw'
        self.rgb_topic = f'{ns}/oakd/rgb/image_raw/compressed'
        self.info_topic = f'{ns}/oakd/rgb/camera_info'

        self.oakd_yolo = YOLO(amr_model_path)
        self.get_logger().info("AMR YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

        self.target_class = "customer_b"

        self.K = None
        self.depth_image = None
        self.rgb_image = None
        self.yolo_running = False

        # OAK-D YOLO ì´ë¯¸ì§€ í¼ë¸”ë¦¬ì…”
        self.qos_image = QoSProfile(
            history=QoSHistoryPolicy.KEEP_LAST,
            depth=1,
            reliability=QoSReliabilityPolicy.BEST_EFFORT
        )
        self.oakd_yolo_image_pub = self.create_publisher(
            Image, '/amr2/annotated_frame', self.qos_image
        )

        # cmd_vel í¼ë¸”ë¦¬ì…”
        self.cmd_vel_pub = self.create_publisher(
            Twist, f'{ns}/cmd_vel', 10
        )

        # ===== ì¶”ì  íŒŒë¼ë¯¸í„° =====
        self.follow_distance = 1.1
        self.k_v = 0.8
        self.k_w = 1.2
        self.max_linear_speed = 0.25
        self.max_angular_speed = 0.5
        self.dist_deadband = 0.05
        self.angle_deadband = 0.17

        self.lost_timeout = 1.0
        self.search_angular_speed = 0.5
        self.search_duration = 2 * math.pi / abs(self.search_angular_speed)

        # ===== ìƒíƒœ ê´€ë¦¬ =====
        # ìƒíƒœ: "WEBCAM_DETECTION", "NAVIGATING", "OAKD_SEARCHING", "OAKD_TRACKING"
        self.state = "WEBCAM_DETECTION"
        self.last_detection_time = None
        self.search_start_time = None

        # ðŸ”¹ OAK-D ì¶”ì  ì™„ì „ ìƒì‹¤ íƒ€ì´ë¨¸ (íƒ€ê²Ÿì´ ì‹œì•¼ë¥¼ ì™„ì „ížˆ ë²—ì–´ë‚œ ê²½ìš° íŒë‹¨)
        self.oakd_lost_timeout = 3.0  # 3ì´ˆê°„ ë¯¸ê²€ì¶œ ì‹œ ì›¹ìº  ëª¨ë“œë¡œ ë³µê·€

        # ===== TurtleBot4 ë„¤ë¹„ê²Œì´í„° ì´ˆê¸°í™” =====
        self.navigator = TurtleBot4Navigator()

        if not self.navigator.getDockedStatus():
            self.get_logger().info('Docking before initializing pose')
            self.navigator.dock()

        initial_pose = self.navigator.getPoseStamped(
            [-3.95146, 3.98198],
            TurtleBot4Directions.NORTH
        )
        self.navigator.setInitialPose(initial_pose)
        self.navigator.waitUntilNav2Active()
        self.navigator.undock()

        # ===== OAK-D ì¹´ë©”ë¼ ì„œë¸ŒìŠ¤í¬ë¦½ì…˜ =====
        self.create_subscription(
            CameraInfo, self.info_topic,
            self.camera_info_callback, self.qos_sensor
        )
        self.create_subscription(
            Image, self.depth_topic,
            self.depth_callback, self.qos_sensor
        )
        self.create_subscription(
            CompressedImage, self.rgb_topic,
            self.rgb_callback, self.qos_sensor
        )

        self.logged_intrinsics = False
        self.logged_rgb_shape = False
        self.logged_depth_shape = False

        # ===== íƒ€ì´ë¨¸ ì„¤ì • =====
        # ì›¹ìº  ê²€ì¶œ ë£¨í”„ (0.5ì´ˆë§ˆë‹¤)
        self.webcam_timer = self.create_timer(1.0, self.webcam_detection_loop)
        
        # OAK-D ì²˜ë¦¬ëŠ” 5ì´ˆ í›„ ì‹œìž‘ (TF Tree ì•ˆì •í™”)
        self.get_logger().info("TF Tree ì•ˆì •í™” ëŒ€ê¸° ì¤‘... 5ì´ˆ í›„ OAK-D í™œì„±í™”")
        self.start_timer = self.create_timer(5.0, self.start_oakd_processing)

    # ========================================
    # OAK-D ì´ˆê¸°í™” í•¨ìˆ˜
    # ========================================
    def start_oakd_processing(self):
        self.get_logger().info("TF Tree ì•ˆì •í™” ì™„ë£Œ. OAK-D ì²˜ë¦¬ ì‹œìž‘.")
        self.oakd_timer = self.create_timer(0.2, self.oakd_process_frame)
        self.start_timer.cancel()

    # ========================================
    # ì›¹ìº  ê´€ë ¨ í•¨ìˆ˜ë“¤ (MoveRobot íŒŒíŠ¸)
    # ========================================
    def get_quadrant(self, xc, yc, frame_cx, frame_cy):
        """ì´ë¯¸ì§€ ì¤‘ì‹¬ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ë¶„ë©´ ê³„ì‚°"""
        if (xc >= frame_cx) and (yc <= frame_cy):
            return 1
        elif (xc <= frame_cx) and (yc <= frame_cy):
            return 2
        elif (xc <= frame_cx) and (yc >= frame_cy):
            return 3
        else:
            return 4

    def send_nav2_goal(self, x, y, theta):
        """Nav2 ëª©í‘œ ì¢Œí‘œë¡œ NavigateToPose ì „ì†¡"""
        if not self._action_client.wait_for_server(timeout_sec=1.0):
            self.get_logger().warn('[WARN] Nav2 Action ì„œë²„ì— ì ‘ì†í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
            return

        quats = quaternion_from_euler(0.0, 0.0, theta)
        
        goal_msg = NavigateToPose.Goal()
        goal_msg.pose.header.frame_id = 'map'
        goal_msg.pose.header.stamp = self.get_clock().now().to_msg()
        goal_msg.pose.pose.position.x = x
        goal_msg.pose.pose.position.y = y
        goal_msg.pose.pose.orientation.z = quats[2]
        goal_msg.pose.pose.orientation.w = quats[3]

        self.get_logger().info(f'[INFO] ìƒˆë¡œìš´ ëª©í‘œ ì¢Œí‘œë¡œ ì´ë™: ({x:.2f}, {y:.2f})')
        
        # ë¹„ë™ê¸°ë¡œ goal ì „ì†¡ ë° ê²°ê³¼ ì½œë°± ë“±ë¡
        send_goal_future = self._action_client.send_goal_async(goal_msg)
        send_goal_future.add_done_callback(self.navigation_goal_response_callback)
        
        self.navigation_in_progress = True
        self.state = "NAVIGATING"

    def navigation_goal_response_callback(self, future):
        """Navigation goalì´ ìˆ˜ë½ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        self.navigation_goal_handle = future.result()
        if not self.navigation_goal_handle.accepted:
            self.get_logger().warn('Navigation goalì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.')
            self.navigation_in_progress = False
            self.state = "WEBCAM_DETECTION"
            return

        self.get_logger().info('Navigation goalì´ ìˆ˜ë½ë˜ì—ˆìŠµë‹ˆë‹¤.')
        
        # ê²°ê³¼ ëŒ€ê¸°
        result_future = self.navigation_goal_handle.get_result_async()
        result_future.add_done_callback(self.navigation_result_callback)

    def navigation_result_callback(self, future):
        """Navigation ì™„ë£Œ ì‹œ í˜¸ì¶œ"""
        result = future.result().result
        status = future.result().status
        
        self.navigation_in_progress = False
        
        if status == 4:  # SUCCEEDED
            self.get_logger().info('ëª©í‘œ ì§€ì  ë„ì°© ì™„ë£Œ! OAK-D íƒìƒ‰ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.')
            self.state = "OAKD_SEARCHING"
            self.search_start_time = None
        else:
            self.get_logger().warn(f'Navigation ì‹¤íŒ¨ (status: {status}). ì›¹ìº  ëª¨ë“œë¡œ ë³µê·€.')
            self.state = "WEBCAM_DETECTION"

    def webcam_detection_loop(self):
        """ì›¹ìº ì—ì„œ YOLO ê²€ì¶œ ë° ì‚¬ë¶„ë©´ íŒë‹¨"""
        # ðŸ”¹ OAK-D ì¶”ì  ì¤‘(OAKD_TRACKING)ì´ë©´ ì›¹ìº  ê²€ì¶œì€ í•˜ë˜ Navigation ëª…ë ¹ì€ ë³´ë‚´ì§€ ì•ŠìŒ
        # ðŸ”¹ NAVIGATING ë˜ëŠ” OAKD_SEARCHING ì¤‘ì—ëŠ” ì‚¬ë¶„ë©´ ë³€ê²½ ì‹œ ì¦‰ì‹œ ìž¬ì„¤ì •
        
        ret, frame = self.cap.read()
        if not ret:
            self.get_logger().warn("ì›¹ìº  í”„ë ˆìž„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        h, w = frame.shape[:2]
        origin = (w//2, h//2)

        results = self.webcam_model.predict(frame, classes=DETECT_TARGET, conf=0.5, verbose=False)
        annotated_frame = frame.copy()

        new_quadrant = -1
        
        for r in results:
            if len(r.boxes) > 0:
                box = r.boxes[0]
                x1, y1, x2, y2 = [int(val) for val in box.xyxy[0].tolist()]
                
                cx = (x1 + x2) / 2
                cy = (y1 + y2) / 2

                new_quadrant = get_quadrant((cx, cy), origin, self.axis_angle)

                cv2.rectangle(annotated_frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)
                cv2.circle(annotated_frame, (int(cx), int(cy)), 3, (0, 255, 255), -1)
                annotated_frame = draw_rotated_axis(annotated_frame, origin, self.axis_angle, axis_length=700)
                text = f"Q{new_quadrant}"
                cv2.putText(annotated_frame, text, (int(x1), int(y1) - 5),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
                break

        # Annotated ì´ë¯¸ì§€ í¼ë¸”ë¦¬ì‹œ
        try:
            ros_image_msg = self.bridge.cv2_to_imgmsg(annotated_frame, "bgr8")
            self.webcam_image_publisher.publish(ros_image_msg)
        except Exception as e:
            self.get_logger().error(f'Webcam frame ë°œí–‰ ì‹¤íŒ¨: {e}')

        # ðŸ”¹ ì‚¬ë¶„ë©´ ë³€ê²½ ê°ì§€ ë° Navigation ì¤‘ë‹¨/ìž¬ì‹œìž‘
        # OAKD_TRACKING ìƒíƒœì¼ ë•ŒëŠ” ì›¹ìº  ëª…ë ¹ì„ ë¬´ì‹œ (OAK-D ì¶”ì  ìš°ì„ )
        if new_quadrant != -1 and new_quadrant != self.previous_quadrant:
            self.get_logger().info(
                f"ì›¹ìº  ì‚¬ë¶„ë©´ ë³€ê²½ ê°ì§€: {self.previous_quadrant} -> {new_quadrant}"
            )
            
            # OAKD_TRACKING ì¤‘ì´ë©´ ì›¹ìº  ëª…ë ¹ ë¬´ì‹œ
            if self.state == "OAKD_TRACKING":
                self.get_logger().info(
                    "OAK-D ì¶”ì  ì¤‘ì´ë¯€ë¡œ ì›¹ìº  ì‚¬ë¶„ë©´ ë³€ê²½ ë¬´ì‹œ (ì¶”ì  ìš°ì„ )"
                )
                # previous_quadrantëŠ” ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠìŒ (ì¶”ì  ëë‚œ í›„ ë¹„êµë¥¼ ìœ„í•´)
                return
            
            # NAVIGATING ë˜ëŠ” OAKD_SEARCHING ì¤‘ì´ë©´ ì¦‰ì‹œ ì¤‘ë‹¨í•˜ê³  ìž¬ì„¤ì •
            if self.state in ["NAVIGATING", "OAKD_SEARCHING"]:
                self.get_logger().info("ê¸°ì¡´ ë™ìž‘ ì¤‘ë‹¨. ìƒˆë¡œìš´ ëª©í‘œë¡œ ìž¬ì„¤ì •.")
                # Navigation ì·¨ì†Œ
                if self.navigation_goal_handle is not None:
                    self.navigation_goal_handle.cancel_goal_async()
                
                # ë¡œë´‡ ì •ì§€
                self.stop_robot()
            
            # ìƒˆë¡œìš´ ëª©í‘œë¡œ Navigation ì‹œìž‘
            x, y, theta = QUADRANT_TARGET_POSES[new_quadrant]
            self.send_nav2_goal(x, y, theta)
            self.previous_quadrant = new_quadrant

    # ========================================
    # OAK-D ì¹´ë©”ë¼ ì½œë°± í•¨ìˆ˜ë“¤
    # ========================================
    def camera_info_callback(self, msg):
        with self.lock:
            self.K = np.array(msg.k).reshape(3, 3)
            if not self.logged_intrinsics:
                self.get_logger().info(
                    f"Camera intrinsics: fx={self.K[0,0]:.2f}, fy={self.K[1,1]:.2f}"
                )
                self.logged_intrinsics = True

    def depth_callback(self, msg):
        now = self.get_clock().now()
        now_sec = now.nanoseconds * 1e-9
        msg_sec = msg.header.stamp.sec + msg.header.stamp.nanosec * 1e-9
        dt = now_sec - msg_sec
        
        if dt > 1.0:
            self.get_logger().warn(f"Depth frame too old ({dt:.2f}s). Dropping.")
            return

        try:
            depth = self.bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')
            
            if depth is None or depth.size == 0:
                self.get_logger().error("Depth image is empty")
            else:
                if not self.logged_depth_shape:
                    self.get_logger().info(f"Depth image: {depth.shape}")
                    self.logged_depth_shape = True

            with self.lock:
                self.depth_image = depth

        except Exception as e:
            self.get_logger().error(f"Depth conversion failed: {e}")

    def rgb_callback(self, msg):
        now = self.get_clock().now()
        now_sec = now.nanoseconds * 1e-9
        msg_sec = msg.header.stamp.sec + msg.header.stamp.nanosec * 1e-9
        dt = now_sec - msg_sec

        if dt > 0.5:
            self.get_logger().warn(f"RGB frame too old ({dt:.2f}s). Dropping.")
            return

        try:
            np_arr = np.frombuffer(msg.data, np.uint8)
            rgb = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)

            if rgb is None or rgb.size == 0:
                self.get_logger().error("Decoded RGB image is empty")
            else:
                if not self.logged_rgb_shape:
                    self.get_logger().info(f"RGB image: {rgb.shape}")
                    self.logged_rgb_shape = True

            with self.lock:
                self.rgb_image = rgb

        except Exception as e:
            self.get_logger().error(f"RGB decode failed: {e}")

    # ========================================
    # OAK-D í”„ë ˆìž„ ì²˜ë¦¬ (YOLO + ì¶”ì )
    # ========================================
    def oakd_process_frame(self):
        """OAK-D ì¹´ë©”ë¼ë¡œ íƒ€ê²Ÿ íƒìƒ‰ ë° ì¶”ì """
        # OAKD_SEARCHING ë˜ëŠ” OAKD_TRACKING ìƒíƒœì¼ ë•Œë§Œ ì²˜ë¦¬
        if self.state not in ["OAKD_SEARCHING", "OAKD_TRACKING"]:
            return

        if self.yolo_running:
            return

        with self.lock:
            rgb = self.rgb_image.copy() if self.rgb_image is not None else None
            depth = self.depth_image.copy() if self.depth_image is not None else None

        if rgb is None:
            return

        self.yolo_running = True
        now = self.get_clock().now()

        try:
            rgb_display = rgb.copy()
            boxes = self.run_oakd_yolo(rgb_display)

            target_found = False
            target_cx = None
            target_cy = None
            target_dist = None

            MIN_CONF = 0.9

            best_box = None
            best_conf = 0.0

            # íƒ€ê²Ÿ í´ëž˜ìŠ¤ì—ì„œ ê°€ìž¥ ë†’ì€ confidence ë°•ìŠ¤ ì°¾ê¸°
            for (x1, y1, x2, y2, name, conf) in boxes:
                if name == self.target_class and conf > best_conf:
                    best_conf = conf
                    best_box = (x1, y1, x2, y2, name, conf)

            # ì‹œê°í™”
            if best_box is not None and best_conf >= MIN_CONF:
                x1, y1, x2, y2, name, conf = best_box
                cv2.rectangle(rgb_display, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(
                    rgb_display, f"{name} {conf:.2f}",
                    (x1, max(0, y1 - 5)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2
                )

            # YOLO ê²°ê³¼ ì´ë¯¸ì§€ í¼ë¸”ë¦¬ì‹œ
            img_msg = self.bridge.cv2_to_imgmsg(rgb_display, encoding='bgr8')
            img_msg.header.stamp = now.to_msg()
            img_msg.header.frame_id = 'oakd_rgb_frame'
            self.oakd_yolo_image_pub.publish(img_msg)

            # ê±°ë¦¬ ê³„ì‚°
            if best_box is not None and best_conf >= MIN_CONF and depth is not None:
                x1, y1, x2, y2, name, conf = best_box
                cx = int((x1 + x2) / 2)
                cy = int(y2 - (y2 - y1) * 0.05)

                if 0 <= cy < depth.shape[0] and 0 <= cx < depth.shape[1]:
                    z = float(depth[cy, cx]) / 1000.0
                    if 0.2 < z < 5.0:
                        target_found = True
                        target_cx = cx
                        target_cy = cy
                        target_dist = z

            # ðŸ”¹ íƒ€ê²Ÿ ë°œê²¬ ì‹œ ì¶”ì  ëª¨ë“œë¡œ ì „í™˜ (ì›¹ìº  ëª…ë ¹ë³´ë‹¤ ìš°ì„ )
            if target_found:
                self.last_detection_time = now
                
                # íƒìƒ‰ ì¤‘ì—ì„œ ì¶”ì ìœ¼ë¡œ ì „í™˜
                if self.state == "OAKD_SEARCHING":
                    self.get_logger().info("OAK-Dì—ì„œ íƒ€ê²Ÿ ë°œê²¬! ì¶”ì  ëª¨ë“œë¡œ ì „í™˜")
                
                self.state = "OAKD_TRACKING"
                self.search_start_time = None
                self.track_target(target_cx, target_cy, target_dist, rgb.shape)
                
            else:
                # ðŸ”¹ íƒ€ê²Ÿ ë¯¸ë°œê²¬ ì²˜ë¦¬
                if self.state == "OAKD_SEARCHING":
                    # ê³„ì† 360ë„ íšŒì „ íƒìƒ‰
                    self.search_for_target(now)
                    
                elif self.state == "OAKD_TRACKING":
                    # ðŸ”¹ ì¶”ì  ì¤‘ íƒ€ê²Ÿì„ ë†“ì¹œ ê²½ìš°
                    if self.last_detection_time is None:
                        # ì´ì „ì—ë„ ì—†ì—ˆìœ¼ë©´ íƒìƒ‰ ëª¨ë“œë¡œ
                        self.get_logger().info("íƒ€ê²Ÿ ë¯¸ë°œê²¬. íƒìƒ‰ ëª¨ë“œë¡œ ì „í™˜")
                        self.state = "OAKD_SEARCHING"
                        self.search_start_time = None
                        self.stop_robot()
                    else:
                        elapsed = (now - self.last_detection_time).nanoseconds * 1e-9
                        
                        if elapsed < self.lost_timeout:
                            # 1ì´ˆ ì´ë‚´: ìž ì‹œ ëŒ€ê¸° (ì¶”ì  ìœ ì§€)
                            self.stop_robot()
                        elif elapsed < self.oakd_lost_timeout:
                            # 1~3ì´ˆ: ì œìžë¦¬ íšŒì „ìœ¼ë¡œ ìž¬íƒìƒ‰ ì‹œë„
                            if self.search_start_time is None:
                                self.get_logger().info(
                                    "íƒ€ê²Ÿ ë†“ì¹¨. ì œìžë¦¬ íšŒì „ìœ¼ë¡œ ìž¬íƒìƒ‰ ì‹œìž‘"
                                )
                                self.search_start_time = now
                            self.search_for_target(now)
                        else:
                            # ðŸ”¹ 3ì´ˆ ì´ìƒ: ì™„ì „ížˆ ì‹œì•¼ë¥¼ ë²—ì–´ë‚¨ â†’ ì›¹ìº  ëª¨ë“œë¡œ ë³µê·€
                            self.get_logger().info(
                                "íƒ€ê²Ÿì´ OAK-D ì‹œì•¼ë¥¼ ì™„ì „ížˆ ë²—ì–´ë‚¨. ì›¹ìº  ëª¨ë“œë¡œ ë³µê·€í•˜ì—¬ ìž¬íƒì§€ ì‹œìž‘."
                            )
                            self.state = "WEBCAM_DETECTION"
                            self.stop_robot()
                            self.last_detection_time = None
                            self.search_start_time = None

        except Exception as e:
            self.get_logger().warn(f"OAK-D í”„ë ˆìž„ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        finally:
            self.yolo_running = False

    def track_target(self, cx, cy, dist, image_shape):
        """íƒ€ê²Ÿì„ ì¼ì • ê±°ë¦¬ ìœ ì§€í•˜ë©° ì¶”ì """
        height, width, _ = image_shape

        center_x = width / 2.0
        error_x = (cx - center_x) / center_x

        dist_error = dist - self.follow_distance

        if abs(dist_error) < self.dist_deadband:
            dist_error = 0.0

        if abs(error_x) < self.angle_deadband:
            error_x = 0.0

        linear_x = self.k_v * dist_error
        if dist < self.follow_distance and dist_error <= 0:
            linear_x = 0.0

        angular_z = -self.k_w * error_x

        linear_x = max(min(linear_x, self.max_linear_speed), -self.max_linear_speed)
        angular_z = max(min(angular_z, self.max_angular_speed), -self.max_angular_speed)

        if linear_x == 0.0 and angular_z == 0.0:
            self.stop_robot()
            return

        twist = Twist()
        twist.linear.x = float(linear_x)
        twist.angular.z = float(angular_z)
        self.cmd_vel_pub.publish(twist)

    def search_for_target(self, now):
        """ì œìžë¦¬ì—ì„œ 360ë„ íšŒì „í•˜ë©° íƒ€ê²Ÿ íƒìƒ‰"""
        if self.search_start_time is None:
            self.search_start_time = now
            self.get_logger().info("OAK-D 360ë„ íšŒì „ íƒìƒ‰ ì‹œìž‘")

        elapsed = (now - self.search_start_time).nanoseconds * 1e-9

        if elapsed < self.search_duration:
            twist = Twist()
            twist.linear.x = 0.0
            twist.angular.z = float(self.search_angular_speed)
            self.cmd_vel_pub.publish(twist)
        else:
            self.get_logger().info(
                "360ë„ íƒìƒ‰ ì™„ë£Œ. íƒ€ê²Ÿ ë¯¸ë°œê²¬. ì›¹ìº  ëª¨ë“œë¡œ ë³µê·€."
            )
            self.state = "WEBCAM_DETECTION"
            self.stop_robot()
            self.last_detection_time = None
            self.search_start_time = None

    def stop_robot(self):
        """ë¡œë´‡ ì •ì§€"""
        twist = Twist()
        twist.linear.x = 0.0
        twist.angular.z = 0.0
        self.cmd_vel_pub.publish(twist)

    def run_oakd_yolo(self, rgb_image):
        """OAK-D ì´ë¯¸ì§€ì—ì„œ YOLO ê²€ì¶œ"""
        results = self.oakd_yolo(rgb_image)
        boxes = []
        for r in results:
            for box in r.boxes:
                x1, y1, x2, y2 = [int(v) for v in box.xyxy[0]]
                conf = float(box.conf[0])
                cls_id = int(box.cls[0])
                cls_name = self.oakd_yolo.names[cls_id]
                boxes.append((x1, y1, x2, y2, cls_name, conf))
        return boxes

    def destroy_node(self):
        """ë…¸ë“œ ì¢…ë£Œ ì‹œ ì •ë¦¬"""
        if self.cap.isOpened():
            self.cap.release()
        cv2.destroyAllWindows()
        super().destroy_node()


def main():
    rclpy.init()
    node = None
    try:
        node = IntegratedRobotTracker()
        rclpy.spin(node)
    except IOError:
        print("ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨ (IOError). ë…¸ë“œë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"ì˜ˆê¸°ì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        if node is not None:
            node.destroy_node()
        rclpy.shutdown()



if __name__ == "__main__":
    main()